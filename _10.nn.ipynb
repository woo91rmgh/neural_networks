{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building an Image Classifier\n",
    "- Start with Sequential API to classify and regress (declarative model i.e. we outline the structure of layers upfont)\n",
    "- then Functional API model (declarative) where each layer is a function on some other layer (not in sequence), with one o many inputs (if we want to split some featues and tain them diffeently), on or many outputs (if we want to have multiple outputs, one for each task, or to regularize model with an auxiliary output to prevent overfitting)\n",
    "- then Subclassing API to build Dynamic Models (not declarative) - if we need to loop, or if-statement to connect layers in a dynamic way. Very flexible but difficult to track errors, save or clone\n",
    "- Also, Models can be combined! - each model can be treated just as an ordinary layer and connected with others to form a chain or a super model\n",
    "\n",
    "<img src=\"screenshots/ch_11/2023-01-24-19-51-57.png\" width=\"600px\" img/>\n",
    "<img src=\"screenshots/ch_10/2023-01-24-19-49-07.png\" width=\"600px\" img/>\n",
    "<img src=\"screenshots/ch_10/2023-01-24-19-55-52.png\" width=\"600px\" img/>\n",
    "\n",
    "<img src=\"screenshots/ch_10/2023-01-24-19-56-39.png\" width=\"600px\" img/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ann\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n",
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading the fashion MNIST dataset. Keras has a number of functions to load popular datasets in keras.datasets. The dataset is already split for you between a training set and a test set, but it can be useful to split the training set further to have a validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (60000, 28, 28)\n",
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n",
      "uint8\n",
      "0 255\n",
      "<class 'numpy.ndarray'> (60000,) uint8\n",
      "[9 0 0 ... 3 0 5]\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "# if SSL errror: I came across this problem as well. I did some digging and found that the problem was that I didn't have the right certificates installed for Python3. Fairly easy fix on a Mac - run the file located at Applications>Python 3.X>Install Certificates.command and that should do the trick.\n",
    "\n",
    "print(type(X_train_full),X_train_full.shape)\n",
    "\n",
    "# each pic is 28x28 pixels i.e. 28 rows with 28 elements in each row:\n",
    "print(X_train_full[:2])\n",
    "#Each pixel intensity is represented as a byte (0 to 255):\n",
    "print(X_train_full.dtype)\n",
    "print(X_train_full.min(),X_train_full.max())\n",
    "\n",
    "#The labels are the class IDs (represented as uint8), from 0 to 9:\n",
    "print(type(y_train_full),y_train_full.shape, y_train_full.dtype)\n",
    "print(y_train_full)\n",
    "\n",
    "# Here are the corresponding class names:\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the full training set into a validation set and a (smaller) training set. \n",
    "We also scale (a must for NNs) the pixel intensities down to the 0-1 range and convert them to floats, by dividing by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can plot an image using Matplotlib's imshow() function, with a 'binary' color map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coat\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_to_show=0\n",
    "\n",
    "print(class_names[y_train[image_to_show]])\n",
    "\n",
    "plt.imshow(X_train[image_to_show], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure fashion_mnist_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x345.6 with 40 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_rows = 4\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
    "        plt.axis('off')\n",
    "        plt.title(class_names[y_train[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "save_fig('fashion_mnist_plot', tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiction model using Sequential API\n",
    "- declarative model i.e. each layer needs to be declared in advance\n",
    "- single stack of layers connected sequentially\n",
    "\n",
    "<img src=\"screenshots/ch_10/2023-01-24-19-54-11.png\" width=\"600px\" img/>\n",
    "<img src=\"screenshots/ch_10/2023-01-24-19-58-56.png\" width=\"600px\" img/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model layers [<keras.layers.reshaping.flatten.Flatten object at 0x1609cbbe0>, <keras.layers.core.dense.Dense object at 0x1609bc4a8>, <keras.layers.core.dense.Dense object at 0x1609bc5c0>, <keras.layers.core.dense.Dense object at 0x160a10e80>]\n",
      "<keras.layers.core.dense.Dense object at 0x1609bc4a8>\n",
      "dense_15\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28])) #converts images to \"flat\" 1D array\n",
    "\n",
    "# 1st Dense Hidden layer of 300 neurons with \"relu\" activation.\n",
    "# layer has it's own weight matrix connecting intputs to neutrons. also a vector of bias terms (one per neutron)\n",
    "# it calculates the intial value for each weight (with random start)\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\")) \n",
    "\n",
    "# 2nd Dense Hidden layer of 100 neurons with \"relu\" activation (more aggregated). same logic as above\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "\n",
    "# Final Dense Output layer with 10 neurons - one per target class\n",
    "# Uses Softmax activation function because classes are exclusive\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "### Succinct syntax:\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "print('model layers', model.layers)\n",
    "print(model.layers[1])\n",
    "print(model.layers[1].name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights (784, 300) 6.6012087 [[-0.02123968 -0.02596946  0.05954324 ... -0.06106606 -0.07166125\n",
      "  -0.03965411]\n",
      " [ 0.04891162  0.00478305 -0.07241608 ...  0.04798203 -0.04831857\n",
      "  -0.05488206]\n",
      " [ 0.02345052 -0.07059563 -0.0727627  ...  0.0288062   0.06374887\n",
      "   0.05407514]\n",
      " ...\n",
      " [-0.06780811 -0.01886623 -0.02003569 ... -0.0389171   0.07255684\n",
      "  -0.05953335]\n",
      " [ 0.04758119  0.01428352  0.03311343 ...  0.05484565 -0.068021\n",
      "   0.00730271]\n",
      " [-0.06452577  0.025761    0.07059865 ... -0.02975474 -0.00177423\n",
      "  -0.01088178]]\n",
      "biases (300,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "## Show inital weights\n",
    "weights, biases = model.layers[1].get_weights()\n",
    "\n",
    "print (\"weights\",weights.shape,weights.sum(),weights) # random\n",
    "print (\"biases\",biases.shape,biases) # all set to 0 initially"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# flatten input: 28 x 28 = 784\n",
    "# each input is connected to each neuron in first layer: 784 x 300 + 300 bias vector = 235500 etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compile the model\n",
    "- compile to specify Loss Function and Optimizer, list of Metrics to use\n",
    "- \"sparse_categorical_crossentropy\" - because we have sparse target labels i.e. one label per class\n",
    "    - if it was a prob vector per class e.g. [0,0,0,...1,..0,0] - one-hot vector with 1 out 10 = 1 else 0 - we would use \"categorical_crossentropy\" (to convert from one-hot to sparse: keras.utils.to_categorical(), sparse to one-hot vector: np.argmax(axis=1))\n",
    "    - if we were using Binary classification - would use \"sigmoid\" activation function and loss=\"binary_crossentropy\"\n",
    "\n",
    "- optimizer=\"sgd\" - stochastic gradient decent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "## equivalent to\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(), # with this syntax we need to specify learning rate lr= ?\n",
    "              metrics=[keras.metrics.sparse_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Model\n",
    "- if the y_train classes are very skewed, we can pass \"class_weight\" arg. -> would be used to compute loss\n",
    "- per instance weight can be passed- \"sample_weight\" e.g. if some instance were labeled by experiement, while other by algo (we can give more weight to them)\n",
    "- we can add \"sample_weight\" to validation -> validation_data=(Xval,Yval,\"sample_weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.7275 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.5272 - val_sparse_categorical_accuracy: 0.8200\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4914 - sparse_categorical_accuracy: 0.8287 - val_loss: 0.4382 - val_sparse_categorical_accuracy: 0.8528\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4443 - sparse_categorical_accuracy: 0.8430 - val_loss: 0.5311 - val_sparse_categorical_accuracy: 0.8008\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4169 - sparse_categorical_accuracy: 0.8546 - val_loss: 0.3942 - val_sparse_categorical_accuracy: 0.8640\n",
      "Epoch 5/30\n",
      " 774/1719 [============>.................] - ETA: 1s - loss: 0.4067 - sparse_categorical_accuracy: 0.8578"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-ab4787b2a91d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(X_train, y_train, epochs=30,\n\u001b[0;32m----> 2\u001b[0;31m                     validation_data=(X_valid, y_valid))\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history.params {'verbose': 1, 'epochs': 30, 'steps': 1719}\n",
      "history.epoch [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
      "history.history.keys() {'loss': [0.7159741520881653, 0.4880833923816681, 0.44382816553115845, 0.4171428680419922, 0.3967849016189575, 0.38106757402420044, 0.36826857924461365, 0.35725516080856323, 0.3467704951763153, 0.33713099360466003, 0.3287724554538727, 0.32069361209869385, 0.3134367763996124, 0.3072235584259033, 0.300819456577301, 0.29345670342445374, 0.28818246722221375, 0.2819533050060272, 0.2763616442680359, 0.2712256908416748, 0.2665022015571594, 0.2617855668067932, 0.2572474479675293, 0.2537369132041931, 0.2483634054660797, 0.24533908069133759, 0.24035170674324036, 0.23588407039642334, 0.23210173845291138, 0.22872920334339142], 'sparse_categorical_accuracy': [0.7649636268615723, 0.8291454315185547, 0.843854546546936, 0.8534181714057922, 0.861054539680481, 0.8662727475166321, 0.8690727353096008, 0.8723272681236267, 0.8766727447509766, 0.8794363737106323, 0.8827272653579712, 0.8856182098388672, 0.8875454664230347, 0.8893091082572937, 0.8918545246124268, 0.8943454623222351, 0.8963817954063416, 0.8981817960739136, 0.9004727005958557, 0.9027090668678284, 0.9036545157432556, 0.9062363505363464, 0.9069636464118958, 0.9089636206626892, 0.9107818007469177, 0.9112363457679749, 0.913490891456604, 0.9152363538742065, 0.9175272583961487, 0.9184727072715759], 'val_loss': [0.5012606978416443, 0.45832836627960205, 0.4257166087627411, 0.404609739780426, 0.3920251727104187, 0.37605994939804077, 0.3738980293273926, 0.35592085123062134, 0.35950639843940735, 0.3430540859699249, 0.3364473283290863, 0.32954710721969604, 0.34344473481178284, 0.3404693007469177, 0.32188522815704346, 0.31792616844177246, 0.33369049429893494, 0.3132726848125458, 0.3152553141117096, 0.3153269588947296, 0.34349673986434937, 0.3149086534976959, 0.3143292963504791, 0.31534337997436523, 0.3206789791584015, 0.3017939329147339, 0.30010876059532166, 0.30574387311935425, 0.3048292100429535, 0.3115735948085785], 'val_sparse_categorical_accuracy': [0.8302000164985657, 0.8389999866485596, 0.8578000068664551, 0.8587999939918518, 0.8629999756813049, 0.8715999722480774, 0.8691999912261963, 0.8737999796867371, 0.8736000061035156, 0.8762000203132629, 0.8794000148773193, 0.8813999891281128, 0.8784000277519226, 0.8784000277519226, 0.8855999708175659, 0.8871999979019165, 0.8790000081062317, 0.8870000243186951, 0.8873999714851379, 0.8866000175476074, 0.8744000196456909, 0.8862000107765198, 0.8870000243186951, 0.8862000107765198, 0.8817999958992004, 0.8894000053405762, 0.8942000269889832, 0.8881999850273132, 0.890999972820282, 0.8877999782562256]}\n",
      "history.history.keys() dict_keys(['loss', 'sparse_categorical_accuracy', 'val_loss', 'val_sparse_categorical_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(\"history.params\",history.params)\n",
    "print(\"history.epoch\",history.epoch)\n",
    "print(\"history.history.keys()\",history.history)\n",
    "print(\"history.history.keys()\",history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot loss and accuracy\n",
    "- val error is calculated at the end of each epoch, training is a running mean during each epoch - for better graph it needs to be shifted half an epoch to the left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure keras_learning_curves_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "save_fig(\"keras_learning_curves_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3355 - sparse_categorical_accuracy: 0.8822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33553507924079895, 0.8822000026702881]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test) # output [loss, accuracy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predict\n",
    "take few intances to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.98],\n",
       "       [0.  , 0.  , 0.99, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "[9 2 1]\n",
      "['Ankle boot' 'Pullover' 'Trouser']\n"
     ]
    }
   ],
   "source": [
    "#y_pred = model.predict_classes(X_new) # deprecated\n",
    "y_pred = np.argmax(model.predict(X_new), axis=-1)\n",
    "\n",
    "print(y_pred)\n",
    "print(np.array(class_names)[y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure fashion_mnist_images_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 518.4x172.8 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7.2, 2.4))\n",
    "for index, image in enumerate(X_new):\n",
    "    plt.subplot(1, 3, index + 1)\n",
    "    plt.imshow(image, cmap=\"binary\", interpolation=\"nearest\")\n",
    "    plt.axis('off')\n",
    "    plt.title(class_names[y_test[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "save_fig('fashion_mnist_images_plot', tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression MLP using Sequential API\n",
    "- declarative model i.e. each layer needs to be declared in advance\n",
    "- single output neutro as we want to predict a value\n",
    "- no activation function in the output layer is needed\n",
    "- loss function is MSE\n",
    "\n",
    "<img src=\"screenshots/ch_10/2023-01-24-19-46-32.png\" width=\"600px\" img/>\n",
    "<img src=\"screenshots/ch_10/2023-01-24-19-46-58.png\" width=\"600px\" img/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Let's load, split and scale the California housing dataset (the original one, not the modified one as in chapter 2)\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if the data is noisy like here, use a single layer to prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.6419 - val_loss: 0.8560\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7047 - val_loss: 0.6531\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6345 - val_loss: 0.6099\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 892us/step - loss: 0.5977 - val_loss: 0.5658\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.5706 - val_loss: 0.5355\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5472 - val_loss: 0.5173\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5288 - val_loss: 0.5081\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5130 - val_loss: 0.4799\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4992 - val_loss: 0.4690\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4875 - val_loss: 0.4656\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 907us/step - loss: 0.4777 - val_loss: 0.4482\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.4688 - val_loss: 0.4479\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 940us/step - loss: 0.4615 - val_loss: 0.4296\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 981us/step - loss: 0.4547 - val_loss: 0.4233\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 902us/step - loss: 0.4488 - val_loss: 0.4176\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 914us/step - loss: 0.4435 - val_loss: 0.4123\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4389 - val_loss: 0.4071\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 909us/step - loss: 0.4347 - val_loss: 0.4037\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 913us/step - loss: 0.4306 - val_loss: 0.4000\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4273 - val_loss: 0.3969\n",
      "162/162 [==============================] - 0s 665us/step - loss: 0.4212\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[0.38856643]\n",
      " [1.6792021 ]\n",
      " [3.1022794 ]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complex models with Functional API\n",
    "- declarative model i.e. each layer needs to be declared in advance\n",
    "- each layer is a function of some other layer\n",
    "- can be one or many inputs\n",
    "\n",
    "Not all neural network models are simply sequential. Some may have complex topologies. Some may have multiple inputs and/or multiple outputs. For example, a Wide & Deep neural network (see paper) connects all or part of the inputs directly to the output layer.\n",
    "\n",
    "<img src=\"screenshots/ch_10/2023-01-24-19-38-13.png\" width=\"600px\" img/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_40 (Dense)               (None, 30)           270         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_41 (Dense)               (None, 30)           930         ['dense_40[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 38)           0           ['input_1[0][0]',                \n",
      "                                                                  'dense_41[0][0]']               \n",
      "                                                                                                  \n",
      " dense_42 (Dense)               (None, 1)            39          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_) # hidden1 is a function of input_\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_, hidden2]) # concatenate is a function of 2+ pior layers\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.2611 - val_loss: 3.3940\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6580 - val_loss: 0.9360\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5878 - val_loss: 0.5649\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5582 - val_loss: 0.5712\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5347 - val_loss: 0.5045\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5158 - val_loss: 0.4831\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5002 - val_loss: 0.4639\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4876 - val_loss: 0.4638\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4760 - val_loss: 0.4421\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4659 - val_loss: 0.4313\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4577 - val_loss: 0.4345\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4498 - val_loss: 0.4168\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4428 - val_loss: 0.4230\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4366 - val_loss: 0.4047\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4307 - val_loss: 0.4078\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4257 - val_loss: 0.3938\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4210 - val_loss: 0.3952\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4167 - val_loss: 0.3860\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4121 - val_loss: 0.3827\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4088 - val_loss: 0.4054\n",
      "162/162 [==============================] - 0s 930us/step - loss: 0.4032\n",
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Deep & Wide model\n",
    "- more than one input of features, some inputs go Wide path some Deep, some features are in both inputs!\n",
    "- Wide path - bypasses some layers i.e. go wide off the tree and back to it, skips some layers\n",
    "- Deep path - goes to most or all layes (deep learning) \n",
    "- it allows to learn both deep rules through deep paths (for accuracy) and simple rules through short paths for generalization (to prevent overfitting) (in sequence API all inputs go through all layers, so each input is affected by transformation of each layer - no way to train simple rules)\n",
    "\n",
    "<img src=\"screenshots/ch_10/2023-01-24-19-40-01.png\" width=\"600px\" img/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " deep_input (InputLayer)        [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_43 (Dense)               (None, 30)           210         ['deep_input[0][0]']             \n",
      "                                                                                                  \n",
      " wide_input (InputLayer)        [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_44 (Dense)               (None, 30)           930         ['dense_43[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 35)           0           ['wide_input[0][0]',             \n",
      "                                                                  'dense_44[0][0]']               \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            36          ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,176\n",
      "Trainable params: 1,176\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will send 5 features (features 0 to 4), and 6 through the deep path (features 2 to 7). Note that 3 features will go through both (features 2, 3 and 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.8145 - val_loss: 0.8072\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6771 - val_loss: 0.6658\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5979 - val_loss: 0.5687\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5584 - val_loss: 0.5296\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5334 - val_loss: 0.4993\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5120 - val_loss: 0.4811\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4970 - val_loss: 0.4696\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4843 - val_loss: 0.4496\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4730 - val_loss: 0.4404\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4644 - val_loss: 0.4315\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4570 - val_loss: 0.4268\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4510 - val_loss: 0.4166\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4462 - val_loss: 0.4125\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4421 - val_loss: 0.4074\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4385 - val_loss: 0.4044\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4356 - val_loss: 0.4007\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4322 - val_loss: 0.4013\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4305 - val_loss: 0.3987\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4274 - val_loss: 0.3934\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4204\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4219\n",
      "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x15febb0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 57ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:] # We will send 5 features (features 0 to 4), and 6 through the deep path (features 2 to 7). Note that 3 features will go through both (features 2, 3 and 4).\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Models with multiple Outputs:\n",
    "- Reasons for multi onputs: \n",
    "-   tasks requires it e.g. we want to locate (regression to find coordinates of the object center) and classify (classification) object in a picture\n",
    "-   Multiple tasks e.g. Multitask Classification -> identify if person on a picture is smilling AND if they wear glasses (these could be run in 2 separate models, but there maybe some learning that can be intechanged between two taks -> better to run a single network)\n",
    "-   Learn something from a part of the network only -> one of the outputs get out in the middle of the network\n",
    "-   Regularization i.e. adding an Axuliary Output somewhere in the middle creates a training contraint, that may reduce overfitting of the ouverall model\n",
    "\n",
    "<img src=\"screenshots/ch_10/2023-01-24-19-41-46.png\" width=\"600px\" img/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " deep_input (InputLayer)        [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_47 (Dense)               (None, 30)           210         ['deep_input[0][0]']             \n",
      "                                                                                                  \n",
      " wide_input (InputLayer)        [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_48 (Dense)               (None, 30)           930         ['dense_47[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 35)           0           ['wide_input[0][0]',             \n",
      "                                                                  'dense_48[0][0]']               \n",
      "                                                                                                  \n",
      " main_output (Dense)            (None, 1)            36          ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " aux_output (Dense)             (None, 1)            31          ['dense_48[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,207\n",
      "Trainable params: 1,207\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2]) # hidden2 is part of the concat function\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2) # hidden2 is also connected to an auxiliary output\n",
    "model = keras.models.Model(inputs=[input_A, input_B],\n",
    "                           outputs=[output, aux_output]) # list both outputs\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"] # we have two outputs some two loss functions\n",
    "            , loss_weights=[0.9, 0.1] # by default it will take average of the two loss functions - so pass weights: 90% for main, an 10% for regularization\n",
    "            , optimizer=keras.optimizers.SGD(learning_rate=1e-3)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.1365 - main_output_loss: 1.9196 - aux_output_loss: 4.0890 - val_loss: 1.6233 - val_main_output_loss: 0.8468 - val_aux_output_loss: 8.6117\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.8905 - main_output_loss: 0.6969 - aux_output_loss: 2.6326 - val_loss: 1.5163 - val_main_output_loss: 0.6836 - val_aux_output_loss: 9.0109\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7429 - main_output_loss: 0.6088 - aux_output_loss: 1.9499 - val_loss: 1.4639 - val_main_output_loss: 0.6229 - val_aux_output_loss: 9.0326\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6771 - main_output_loss: 0.5691 - aux_output_loss: 1.6485 - val_loss: 1.3388 - val_main_output_loss: 0.5481 - val_aux_output_loss: 8.4552\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6381 - main_output_loss: 0.5434 - aux_output_loss: 1.4911 - val_loss: 1.2177 - val_main_output_loss: 0.5194 - val_aux_output_loss: 7.5030\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6079 - main_output_loss: 0.5207 - aux_output_loss: 1.3923 - val_loss: 1.0935 - val_main_output_loss: 0.5106 - val_aux_output_loss: 6.3396\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5853 - main_output_loss: 0.5040 - aux_output_loss: 1.3175 - val_loss: 0.9918 - val_main_output_loss: 0.5115 - val_aux_output_loss: 5.3151\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5666 - main_output_loss: 0.4898 - aux_output_loss: 1.2572 - val_loss: 0.8733 - val_main_output_loss: 0.4733 - val_aux_output_loss: 4.4740\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5504 - main_output_loss: 0.4771 - aux_output_loss: 1.2101 - val_loss: 0.7832 - val_main_output_loss: 0.4555 - val_aux_output_loss: 3.7323\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5373 - main_output_loss: 0.4671 - aux_output_loss: 1.1695 - val_loss: 0.7170 - val_main_output_loss: 0.4604 - val_aux_output_loss: 3.0262\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5266 - main_output_loss: 0.4591 - aux_output_loss: 1.1344 - val_loss: 0.6510 - val_main_output_loss: 0.4293 - val_aux_output_loss: 2.6468\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5173 - main_output_loss: 0.4520 - aux_output_loss: 1.1048 - val_loss: 0.6051 - val_main_output_loss: 0.4310 - val_aux_output_loss: 2.1722\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5095 - main_output_loss: 0.4465 - aux_output_loss: 1.0765 - val_loss: 0.5644 - val_main_output_loss: 0.4161 - val_aux_output_loss: 1.8992\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5027 - main_output_loss: 0.4417 - aux_output_loss: 1.0511 - val_loss: 0.5354 - val_main_output_loss: 0.4119 - val_aux_output_loss: 1.6466\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4967 - main_output_loss: 0.4376 - aux_output_loss: 1.0280 - val_loss: 0.5124 - val_main_output_loss: 0.4047 - val_aux_output_loss: 1.4812\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4916 - main_output_loss: 0.4343 - aux_output_loss: 1.0070 - val_loss: 0.4934 - val_main_output_loss: 0.4034 - val_aux_output_loss: 1.3035\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4867 - main_output_loss: 0.4311 - aux_output_loss: 0.9872 - val_loss: 0.4801 - val_main_output_loss: 0.3984 - val_aux_output_loss: 1.2150\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4829 - main_output_loss: 0.4289 - aux_output_loss: 0.9686 - val_loss: 0.4694 - val_main_output_loss: 0.3962 - val_aux_output_loss: 1.1279\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4785 - main_output_loss: 0.4260 - aux_output_loss: 0.9510 - val_loss: 0.4580 - val_main_output_loss: 0.3936 - val_aux_output_loss: 1.0372\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4756 - main_output_loss: 0.4246 - aux_output_loss: 0.9344 - val_loss: 0.4655 - val_main_output_loss: 0.4048 - val_aux_output_loss: 1.0118\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train] #need to specify separate Target for each output, here is the same\n",
    "                    , epochs=20,\n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]) # same for validation\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- it will return total loss, as well as loss for each output\n",
    "- prediction will do the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4668 - main_output_loss: 0.4178 - aux_output_loss: 0.9082\n",
      "WARNING:tensorflow:6 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1614e0158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 65ms/step\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])\n",
    "\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subclass API to build Dynamic Models\n",
    "- Sequential and Functional models are declerative - layers and structure is declared before model trains - easy to check, debug,confirm, also save and share the model\n",
    "- but some solutions require loops, varying shapes, conditional branching, other dynamic behaviours\n",
    "- another reson is to have more contol over the model\n",
    "- to do it we need to put Model into class, create layers in constructor, and use them to perform computition in Call() method\n",
    "- call() - here comes flexibility: we can do if-statement, loops, low-level tensor flow operations etc.\n",
    "- side-effect -> difficult to tack, cannot save or clone. summary() shows only list of layers, and not how they are connected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of the same model as before but with class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs) # **kwags handles standard args e.g. name\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs): # here comes flexibility: we can do if-statement, loops, low-level tensor flow operations etc.\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "model = WideAndDeepModel(30, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and restoring model\n",
    "- Keras uses HDF5 format, stores model architecture, every layer, hyperparameter, weights and biases, also saves optimizer\n",
    "- altenative is tensorflow SaveModel format\n",
    "- dynamic subclass - no standard saving. we can use save_weights() and load_weights() to save and restore parms, but everything else needs to solved manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")\n",
    "# then\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")\n",
    "# predict\n",
    "model.predict(X_new)\n",
    "\n",
    "# also save weights\n",
    "model.save_weights(\"my_keras_weights.ckpt\")\n",
    "model.load_weights(\"my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit() Callbacks to save incremental outputs\n",
    "- if models is complex and runs long, or data is very large. what if your comp crashes?\n",
    "- model fit() accepts Callbacks arg to specify list of objects to call at the beginning and end of training, or each epoch, or even each processing batch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- example of model \"checkpoint_cb\" - saves by default at each epoch\n",
    "- with \"save_best_only=True\" if will save only if better at this epoch\n",
    "- will save to the same h5 file as the overall model\n",
    "- when we load the model at the end - it will load the best model selected from the entire process!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.8866 - val_loss: 0.7126\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6577 - val_loss: 0.6880\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5934 - val_loss: 0.5803\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5557 - val_loss: 0.5166\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5272 - val_loss: 0.4895\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5033 - val_loss: 0.4951\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4854 - val_loss: 0.4861\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4709 - val_loss: 0.4554\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4578 - val_loss: 0.4413\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4474 - val_loss: 0.4379\n",
      "162/162 [==============================] - 0s 869us/step - loss: 0.4382\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])  \n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model(\"my_keras_model.h5\") # rollback to best model\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit() EarlyStopping to interupt when no sufficent progress\n",
    "- evalutates after a selected number of epochs,(\"patience\" argument) that will roll back to best model\n",
    "- we can therefore set at bigger number of epoch to train\n",
    "- we can combine callbacks to Save (pevent comp crashes) and Earlystopping (to not to waste time)\n",
    "- there are many other callback functions... keras.collbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define custom callback\n",
    "- e.g. to calculate ratio of validation loss over training loss during training (below) or other debugging\n",
    "- callbacks can be implemented during:\n",
    "    - training: on_train_begin(), on_train_end(),on_epoch_begin(), on_epoch_end(),on_batch_begin(), on_batch_end()\n",
    "    - evaluation \"evaluate(...)\": on_test_begin(), on_test_end(),on_test_batch_begin(), on_test_batch_end()\n",
    "    - prediction \"predict(...)\": on_predict_begin(), on_predict_end(),on_predict_batch_begin(), on_predict_batch_end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: custom callback to calculate ratio of validation loss over training loss during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344/363 [===========================>..] - ETA: 0s - loss: 0.4362\n",
      "val/train: 0.94\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4393 - val_loss: 0.4110\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[val_train_ratio_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Board\n",
    "- great to visualize and analyze models\n",
    "- installed automatically with ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to modify output of the model to special binary folder called \"event files\". Each binary data record is called \"summary\". TensorBoard will monitor the directory and update viz if changes. \n",
    "We want to point TensorFlow to a root log directory, and then have a separate subdirectory per model each time it runs, so that we can compare models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./my_logs/run_2022_08_30-14_21_01'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras provides TensorBoard() callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(20, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.5064 - val_loss: 1.3439\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8663 - val_loss: 0.7511\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7497 - val_loss: 0.6723\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6860 - val_loss: 0.6252\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6417 - val_loss: 0.5836\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6052 - val_loss: 0.5526\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5760 - val_loss: 0.5254\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5505 - val_loss: 0.5023\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5288 - val_loss: 0.4826\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5097 - val_loss: 0.4658\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4931 - val_loss: 0.4514\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4786 - val_loss: 0.4390\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4662 - val_loss: 0.4292\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4554 - val_loss: 0.4210\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4459 - val_loss: 0.4140\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4377 - val_loss: 0.4090\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4306 - val_loss: 0.4048\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4246 - val_loss: 0.4019\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 966us/step - loss: 0.4188 - val_loss: 0.4000\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 954us/step - loss: 0.4144 - val_loss: 0.4007\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4100 - val_loss: 0.4015\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4064 - val_loss: 0.4020\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.4028 - val_loss: 0.4037\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 961us/step - loss: 0.3998 - val_loss: 0.4138\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 950us/step - loss: 0.3968 - val_loss: 0.4301\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3945 - val_loss: 0.4339\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3922 - val_loss: 0.4365\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 960us/step - loss: 0.3901 - val_loss: 0.4457\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 947us/step - loss: 0.3880 - val_loss: 0.4409\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 963us/step - loss: 0.3861 - val_loss: 0.4507\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start the TensorBoard server, one option is to open a terminal, if needed activate the virtualenv where you installed TensorBoard, go to this notebook's directory, then type:\n",
    "\n",
    "$ tensorboard --logdir=./my_logs --port=6006\n",
    "\n",
    "You can then open your web browser to localhost:6006 and use TensorBoard. Once you are done, press Ctrl-C in the terminal window, this will shutdown the TensorBoard server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can load TensorBoard's Jupyter extension and run it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-403072d3b5ee3a05\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-403072d3b5ee3a05\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the other available logging options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function __init__ in module keras.callbacks:\n",
      "\n",
      "__init__(self, log_dir='logs', histogram_freq=0, write_graph=True, write_images=False, write_steps_per_second=False, update_freq='epoch', profile_batch=0, embeddings_freq=0, embeddings_metadata=None, **kwargs)\n",
      "    Initialize self.  See help(type(self)) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(keras.callbacks.TensorBoard.__init__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nbr of hidden layers:\n",
    "- even one layer is good, but it requires a lot of neutrons. more efficent to have few hidden layers with less neutrons\n",
    "- real-world data is often build hierarchically to favor more layers e.g. low-level focuses on segments of shapes, mid-level combines low-level into shapes e.g. squares and circles, and high-level and output layers combine low and hid layers into high level structures such as faces\n",
    "- if we want to model hair styles on faces- no need to start from scratch. we can assign weights from a lower layer model that already model faces (\"transfer learning\")\n",
    "- some complex problems require hundreds of layers e.g. speach recognition. but some layers are not connected fully, some leverage other prior learnings that were done at more rudminetary level\n",
    "- too many layers will hower overfit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nbr of neutrons per hidden layer:\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parms optimization options:\n",
    "- https://github.com/hyperopt/hyperopt\n",
    "- https://github.com/maxpumperla/hyperas\n",
    "- https://github.com/Avsecz/kopt\n",
    "- https://github.com/autonomio/talos\n",
    "- https://www.youtube.com/watch?v=Un0JDL3i5Hg&t=24s\n",
    "- https://scikit-optimize.github.io/stable/\n",
    "- https://github.com/JasperSnoek/spearmint\n",
    "- https://github.com/zygmuntz/hyperband\n",
    "- https://github.com/rsteca/sklearn-deap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optimization APIs:\n",
    "- https://cloud.google.com/ai-platform/training/docs/using-hyperparameter-tuning\n",
    "- https://arimo.com/\n",
    "- https://sigopt.com/\n",
    "- http://oscar.calldesk.ai/\n",
    "- https://cloud.google.com/automl/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interesting papers\n",
    "- https://arxiv.org/abs/1603.06560\n",
    "- https://ai.googleblog.com/2018/03/using-evolutionary-automl-to-discover.html\n",
    "- https://www.uber.com/blog/deep-neuroevolution/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example of how to wrap model into scikit_learn wrapper to grid search or randomsearch for parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "put model into a def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wrap with scikit_learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "execute for one parm setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.0896 - val_loss: 20.7721\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7606 - val_loss: 5.0266\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5456 - val_loss: 0.5490\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4732 - val_loss: 0.4529\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4503 - val_loss: 0.4188\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4338 - val_loss: 0.4129\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4241 - val_loss: 0.4004\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4168 - val_loss: 0.3944\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4108 - val_loss: 0.3961\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4060 - val_loss: 0.4071\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4021 - val_loss: 0.3855\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3984 - val_loss: 0.4136\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3951 - val_loss: 0.3997\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3921 - val_loss: 0.3818\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3894 - val_loss: 0.3829\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3869 - val_loss: 0.3739\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.4022\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3829 - val_loss: 0.3873\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3807 - val_loss: 0.3768\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3791 - val_loss: 0.4191\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3774 - val_loss: 0.3927\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3756 - val_loss: 0.4237\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3742 - val_loss: 0.3523\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3725 - val_loss: 0.3842\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3710 - val_loss: 0.4162\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3700 - val_loss: 0.3980\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3691 - val_loss: 0.3473\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3677 - val_loss: 0.3921\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3670 - val_loss: 0.3566\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3653 - val_loss: 0.4191\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3647 - val_loss: 0.3722\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3633 - val_loss: 0.3948\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3632 - val_loss: 0.3423\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3617 - val_loss: 0.3454\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3610 - val_loss: 0.4068\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 951us/step - loss: 0.3608 - val_loss: 0.3417\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3596 - val_loss: 0.3787\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3589 - val_loss: 0.3379\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3582 - val_loss: 0.3419\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3572 - val_loss: 0.3705\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3570 - val_loss: 0.3660\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3563 - val_loss: 0.3803\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3552 - val_loss: 0.3766\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3548 - val_loss: 0.3814\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3543 - val_loss: 0.3326\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3532 - val_loss: 0.3385\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3527 - val_loss: 0.3657\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3521 - val_loss: 0.3576\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3525 - val_loss: 0.3358\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3510 - val_loss: 0.3317\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3504 - val_loss: 0.3564\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3502 - val_loss: 0.3522\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3496 - val_loss: 0.4581\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3497 - val_loss: 0.3808\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3490 - val_loss: 0.3539\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3485 - val_loss: 0.3721\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3479 - val_loss: 0.3336\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3470 - val_loss: 0.4011\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3475 - val_loss: 0.3263\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3465 - val_loss: 0.3271\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3452 - val_loss: 0.3348\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3453 - val_loss: 0.3492\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 989us/step - loss: 0.3444 - val_loss: 0.3401\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3450 - val_loss: 0.3274\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3437 - val_loss: 0.3296\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3431 - val_loss: 0.3307\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 935us/step - loss: 0.3428 - val_loss: 0.3252\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 991us/step - loss: 0.3423 - val_loss: 0.3242\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3419 - val_loss: 0.3254\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3413 - val_loss: 0.3659\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3414 - val_loss: 0.3379\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3405 - val_loss: 0.3272\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3399 - val_loss: 0.3242\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3402 - val_loss: 0.3661\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3397 - val_loss: 0.3284\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3394 - val_loss: 0.3243\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3383 - val_loss: 0.3372\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3384 - val_loss: 0.3366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1596c9b00>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "              validation_data=(X_valid, y_valid),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3412\n"
     ]
    }
   ],
   "source": [
    "mse_test = keras_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d9dbbdbf9a5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_new' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### apply RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8420 - val_loss: 0.4703\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4815 - val_loss: 0.4247\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4519 - val_loss: 0.4052\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4429 - val_loss: 0.3975\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4368 - val_loss: 0.3991\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4340 - val_loss: 0.4031\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4351 - val_loss: 0.4043\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4267 - val_loss: 0.3929\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4258 - val_loss: 0.4040\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4237 - val_loss: 0.3886\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4209 - val_loss: 0.3999\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4170 - val_loss: 0.4085\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4139 - val_loss: 0.3922\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4132 - val_loss: 0.3918\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4106 - val_loss: 0.3886\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4092 - val_loss: 0.3933\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4092 - val_loss: 0.3907\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4087 - val_loss: 0.3955\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4058 - val_loss: 0.3935\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4053 - val_loss: 0.3891\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4251\n",
      "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=   8.3s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7452 - val_loss: 0.4860\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4649 - val_loss: 0.4280\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4495 - val_loss: 0.5791\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4438 - val_loss: 0.4549\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4414 - val_loss: 0.5250\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4409 - val_loss: 0.5486\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4388 - val_loss: 0.5871\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4381 - val_loss: 0.4759\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4371 - val_loss: 0.7523\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4369 - val_loss: 0.7478\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4344 - val_loss: 0.8981\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4347 - val_loss: 0.8543\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.4537\n",
      "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=   5.2s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 10.8725 - val_loss: 4.2468\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1.0257 - val_loss: 0.5794\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5263 - val_loss: 0.4357\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4640 - val_loss: 0.4169\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4515 - val_loss: 0.4135\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4486 - val_loss: 0.4206\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4567 - val_loss: 0.4100\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4495 - val_loss: 0.4155\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4474 - val_loss: 0.4111\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4620 - val_loss: 0.4076\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4470 - val_loss: 0.4062\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4460 - val_loss: 0.4078\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4462 - val_loss: 0.4160\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4445 - val_loss: 0.4158\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4430 - val_loss: 0.4137\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4515 - val_loss: 0.4069\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4422 - val_loss: 0.4119\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4408 - val_loss: 0.4149\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4429 - val_loss: 0.4081\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4595 - val_loss: 0.4141\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4431 - val_loss: 0.4100\n",
      "121/121 [==============================] - 0s 708us/step - loss: 0.4473\n",
      "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=  10.8s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.1684 - val_loss: 6.2480\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6285 - val_loss: 5.2166\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5212 - val_loss: 0.4474\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4280 - val_loss: 0.3901\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4008 - val_loss: 0.3736\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3840 - val_loss: 0.3803\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3730 - val_loss: 0.3813\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3648 - val_loss: 0.3961\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3591 - val_loss: 0.3988\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3542 - val_loss: 0.3891\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3510 - val_loss: 0.3870\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3465 - val_loss: 0.3769\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3424 - val_loss: 0.3770\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3407 - val_loss: 0.3848\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3371 - val_loss: 0.3768\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3560\n",
      "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=   5.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8828 - val_loss: 3.5738\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4887 - val_loss: 0.7767\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4267 - val_loss: 0.5515\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4011 - val_loss: 0.5335\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.5336\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3746 - val_loss: 0.6750\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3678 - val_loss: 0.8462\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3610 - val_loss: 0.8724\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3554 - val_loss: 0.9645\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3525 - val_loss: 0.7225\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3475 - val_loss: 0.7257\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3442 - val_loss: 0.7216\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3422 - val_loss: 0.8440\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3407 - val_loss: 0.7065\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3650\n",
      "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=   5.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0015 - val_loss: 2.9433\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5546 - val_loss: 4.2557\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4854 - val_loss: 2.8526\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4594 - val_loss: 1.6798\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4136 - val_loss: 0.4322\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3937 - val_loss: 0.4172\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.3769\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3753 - val_loss: 0.3688\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3692 - val_loss: 0.4032\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3655 - val_loss: 0.3418\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3610 - val_loss: 0.4452\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3575 - val_loss: 0.3454\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3526 - val_loss: 0.3395\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3503 - val_loss: 0.4354\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3489 - val_loss: 0.3386\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3455 - val_loss: 0.4038\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3434 - val_loss: 0.3302\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3406 - val_loss: 0.3580\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3386 - val_loss: 0.3548\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3360 - val_loss: 0.3459\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3355 - val_loss: 0.3246\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3338 - val_loss: 0.3259\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3315 - val_loss: 0.3443\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3301 - val_loss: 0.3379\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3289 - val_loss: 0.3639\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3271 - val_loss: 0.3903\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3256 - val_loss: 0.3139\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3237 - val_loss: 0.3205\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3261 - val_loss: 0.4282\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3235 - val_loss: 0.3220\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3197 - val_loss: 0.3135\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3177 - val_loss: 0.4312\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3183 - val_loss: 0.3112\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3151 - val_loss: 0.3930\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3179 - val_loss: 0.4466\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3143 - val_loss: 0.6042\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3157 - val_loss: 0.5986\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3197 - val_loss: 0.9304\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3169 - val_loss: 0.4521\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3120 - val_loss: 0.7242\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3137 - val_loss: 0.3448\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3081 - val_loss: 0.5422\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3101 - val_loss: 0.6252\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3169\n",
      "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  16.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.3936 - val_loss: 13.3699\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2098 - val_loss: 10.8972\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4360 - val_loss: 7.7330\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0926 - val_loss: 5.0744\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9168 - val_loss: 3.2363\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8186 - val_loss: 2.1597\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7619 - val_loss: 1.4840\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7266 - val_loss: 1.1083\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7031 - val_loss: 0.8942\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6858 - val_loss: 0.7687\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6720 - val_loss: 0.6947\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6602 - val_loss: 0.6524\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6498 - val_loss: 0.6234\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6401 - val_loss: 0.6061\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6312 - val_loss: 0.5933\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6227 - val_loss: 0.5819\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6147 - val_loss: 0.5733\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6070 - val_loss: 0.5650\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5997 - val_loss: 0.5578\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5926 - val_loss: 0.5508\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5859 - val_loss: 0.5446\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5794 - val_loss: 0.5384\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5732 - val_loss: 0.5326\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5671 - val_loss: 0.5266\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5614 - val_loss: 0.5214\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5558 - val_loss: 0.5166\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5504 - val_loss: 0.5116\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5453 - val_loss: 0.5076\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5403 - val_loss: 0.5035\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5356 - val_loss: 0.4989\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5309 - val_loss: 0.4946\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5265 - val_loss: 0.4915\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5222 - val_loss: 0.4883\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5181 - val_loss: 0.4856\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5141 - val_loss: 0.4828\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5103 - val_loss: 0.4789\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5066 - val_loss: 0.4780\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5030 - val_loss: 0.4742\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4995 - val_loss: 0.4729\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4962 - val_loss: 0.4714\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4929 - val_loss: 0.4686\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4897 - val_loss: 0.4666\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4867 - val_loss: 0.4646\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4837 - val_loss: 0.4636\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4809 - val_loss: 0.4616\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4781 - val_loss: 0.4582\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4755 - val_loss: 0.4581\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4729 - val_loss: 0.4573\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4704 - val_loss: 0.4560\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4680 - val_loss: 0.4544\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4656 - val_loss: 0.4525\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4633 - val_loss: 0.4527\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4611 - val_loss: 0.4522\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4589 - val_loss: 0.4509\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4568 - val_loss: 0.4509\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4548 - val_loss: 0.4513\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4529 - val_loss: 0.4496\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4510 - val_loss: 0.4510\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4491 - val_loss: 0.4502\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4473 - val_loss: 0.4478\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4456 - val_loss: 0.4485\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4440 - val_loss: 0.4488\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4423 - val_loss: 0.4477\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4408 - val_loss: 0.4497\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4392 - val_loss: 0.4512\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4378 - val_loss: 0.4484\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4363 - val_loss: 0.4483\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4349 - val_loss: 0.4494\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4336 - val_loss: 0.4492\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4322 - val_loss: 0.4476\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4309 - val_loss: 0.4481\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4296 - val_loss: 0.4503\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4284 - val_loss: 0.4486\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4272 - val_loss: 0.4491\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4496\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4249 - val_loss: 0.4483\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4238 - val_loss: 0.4474\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4227 - val_loss: 0.4490\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4217 - val_loss: 0.4495\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4206 - val_loss: 0.4468\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4196 - val_loss: 0.4492\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4186 - val_loss: 0.4525\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4177 - val_loss: 0.4504\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4167 - val_loss: 0.4525\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4158 - val_loss: 0.4495\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4148 - val_loss: 0.4548\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4140 - val_loss: 0.4512\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4132 - val_loss: 0.4481\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4123 - val_loss: 0.4472\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4114 - val_loss: 0.4506\n",
      "121/121 [==============================] - 0s 739us/step - loss: 0.4209\n",
      "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  32.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 3.4569 - val_loss: 7.5238\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.5656 - val_loss: 8.6120\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0607 - val_loss: 8.4896\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8953 - val_loss: 7.7423\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8236 - val_loss: 6.8202\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7840 - val_loss: 5.9344\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7579 - val_loss: 5.1492\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7381 - val_loss: 4.4548\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7216 - val_loss: 3.9122\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7071 - val_loss: 3.4233\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6937 - val_loss: 2.9997\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6814 - val_loss: 2.6082\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6701 - val_loss: 2.2766\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6593 - val_loss: 1.9984\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6491 - val_loss: 1.7447\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6395 - val_loss: 1.5300\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6303 - val_loss: 1.3410\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6217 - val_loss: 1.1762\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6133 - val_loss: 1.0345\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6055 - val_loss: 0.9174\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5980 - val_loss: 0.8153\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5908 - val_loss: 0.7363\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5839 - val_loss: 0.6696\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5774 - val_loss: 0.6187\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5711 - val_loss: 0.5778\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5652 - val_loss: 0.5491\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5594 - val_loss: 0.5299\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5540 - val_loss: 0.5199\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5486 - val_loss: 0.5172\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5438 - val_loss: 0.5206\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5389 - val_loss: 0.5312\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5343 - val_loss: 0.5447\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5298 - val_loss: 0.5639\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5256 - val_loss: 0.5821\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5216 - val_loss: 0.6039\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5177 - val_loss: 0.6306\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5140 - val_loss: 0.6564\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5104 - val_loss: 0.6820\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5069 - val_loss: 0.7087\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5160\n",
      "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  14.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.0974 - val_loss: 7.4460\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1844 - val_loss: 5.2071\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4253 - val_loss: 2.9554\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0762 - val_loss: 1.7752\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9094 - val_loss: 1.1201\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8243 - val_loss: 0.8519\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7768 - val_loss: 0.7512\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7473 - val_loss: 0.7064\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7264 - val_loss: 0.6896\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7098 - val_loss: 0.6760\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6955 - val_loss: 0.6687\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6830 - val_loss: 0.6577\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6713 - val_loss: 0.6454\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6604 - val_loss: 0.6355\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6503 - val_loss: 0.6256\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6407 - val_loss: 0.6213\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6317 - val_loss: 0.6120\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6230 - val_loss: 0.6024\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6148 - val_loss: 0.5998\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6072 - val_loss: 0.5901\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5996 - val_loss: 0.5822\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5925 - val_loss: 0.5763\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5857 - val_loss: 0.5664\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5791 - val_loss: 0.5574\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5728 - val_loss: 0.5527\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5668 - val_loss: 0.5452\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5610 - val_loss: 0.5437\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5555 - val_loss: 0.5366\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5501 - val_loss: 0.5322\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5450 - val_loss: 0.5264\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5399 - val_loss: 0.5234\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5352 - val_loss: 0.5175\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5305 - val_loss: 0.5137\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5262 - val_loss: 0.5078\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5219 - val_loss: 0.5045\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5178 - val_loss: 0.4970\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5139 - val_loss: 0.4911\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5101 - val_loss: 0.4887\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5064 - val_loss: 0.4847\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5029 - val_loss: 0.4815\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4994 - val_loss: 0.4776\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4962 - val_loss: 0.4736\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4930 - val_loss: 0.4706\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4901 - val_loss: 0.4673\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4871 - val_loss: 0.4655\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4843 - val_loss: 0.4625\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4816 - val_loss: 0.4576\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4789 - val_loss: 0.4554\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4764 - val_loss: 0.4525\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4740 - val_loss: 0.4495\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4716 - val_loss: 0.4468\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4693 - val_loss: 0.4446\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4670 - val_loss: 0.4420\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4649 - val_loss: 0.4394\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4628 - val_loss: 0.4373\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4607 - val_loss: 0.4349\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4588 - val_loss: 0.4330\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4569 - val_loss: 0.4311\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4550 - val_loss: 0.4291\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4532 - val_loss: 0.4277\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4515 - val_loss: 0.4257\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4498 - val_loss: 0.4241\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4482 - val_loss: 0.4224\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4466 - val_loss: 0.4208\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4451 - val_loss: 0.4193\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4436 - val_loss: 0.4180\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4422 - val_loss: 0.4164\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4408 - val_loss: 0.4151\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4395 - val_loss: 0.4141\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4382 - val_loss: 0.4124\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4369 - val_loss: 0.4112\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4357 - val_loss: 0.4101\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4345 - val_loss: 0.4088\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4334 - val_loss: 0.4081\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4323 - val_loss: 0.4073\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4312 - val_loss: 0.4070\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4301 - val_loss: 0.4056\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4291 - val_loss: 0.4040\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4281 - val_loss: 0.4034\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4271 - val_loss: 0.4033\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4262 - val_loss: 0.4019\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4008\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4244 - val_loss: 0.4002\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4236 - val_loss: 0.3996\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4227 - val_loss: 0.3983\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4219 - val_loss: 0.3980\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4211 - val_loss: 0.3981\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4203 - val_loss: 0.3969\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4195 - val_loss: 0.3978\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4188 - val_loss: 0.3961\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4180 - val_loss: 0.3951\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4173 - val_loss: 0.3938\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4166 - val_loss: 0.3938\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4159 - val_loss: 0.3935\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4152 - val_loss: 0.3934\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4146 - val_loss: 0.3932\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4139 - val_loss: 0.3939\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4132 - val_loss: 0.3913\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4127 - val_loss: 0.3916\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4121 - val_loss: 0.3918\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4139\n",
      "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  36.3s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.0765 - val_loss: 1.3536\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7485 - val_loss: 0.7463\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6415 - val_loss: 0.5899\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5900 - val_loss: 0.5366\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5507 - val_loss: 0.5063\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5188 - val_loss: 0.4813\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4926 - val_loss: 0.4639\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4721 - val_loss: 0.4427\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4552 - val_loss: 0.4393\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4420 - val_loss: 0.4137\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4313 - val_loss: 0.4071\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4224 - val_loss: 0.3983\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4147 - val_loss: 0.3933\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4089 - val_loss: 0.3972\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4029 - val_loss: 0.3852\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3986 - val_loss: 0.3830\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3939 - val_loss: 0.3947\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3900 - val_loss: 0.3713\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3857 - val_loss: 0.3752\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3828 - val_loss: 0.3741\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3803 - val_loss: 0.3782\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3766 - val_loss: 0.3637\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3742 - val_loss: 0.3723\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3721 - val_loss: 0.3707\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3691 - val_loss: 0.4047\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3679 - val_loss: 0.3839\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3654 - val_loss: 0.4167\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3637 - val_loss: 0.3500\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3607 - val_loss: 0.3792\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3602 - val_loss: 0.3636\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3576 - val_loss: 0.3476\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3566 - val_loss: 0.3566\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3548 - val_loss: 0.3611\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3541 - val_loss: 0.3414\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3527 - val_loss: 0.3474\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3508 - val_loss: 0.3944\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3507 - val_loss: 0.4402\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3502 - val_loss: 0.4723\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3496 - val_loss: 0.3722\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3481 - val_loss: 0.4019\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3467 - val_loss: 0.3376\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3449 - val_loss: 0.3377\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3450 - val_loss: 0.3354\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3433 - val_loss: 0.3737\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3441 - val_loss: 0.3336\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3421 - val_loss: 0.3562\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3415 - val_loss: 0.3547\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3410 - val_loss: 0.3399\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3400 - val_loss: 0.3304\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3395 - val_loss: 0.3850\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3393 - val_loss: 0.3430\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3382 - val_loss: 0.3363\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3378 - val_loss: 0.3387\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3373 - val_loss: 0.3294\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3361 - val_loss: 0.3655\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3369 - val_loss: 0.3310\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3354 - val_loss: 0.3728\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3347 - val_loss: 0.3375\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3340 - val_loss: 0.3263\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3331 - val_loss: 0.3402\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3329 - val_loss: 0.3440\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3321 - val_loss: 0.3582\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3320 - val_loss: 0.3303\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3311 - val_loss: 0.3680\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3311 - val_loss: 0.3293\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3311 - val_loss: 0.3276\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3299 - val_loss: 0.3563\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3294 - val_loss: 0.3297\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3282 - val_loss: 0.3445\n",
      "121/121 [==============================] - 0s 799us/step - loss: 0.3551\n",
      "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=  27.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.8880 - val_loss: 3.4090\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7244 - val_loss: 1.6754\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6372 - val_loss: 0.9319\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5910 - val_loss: 0.6042\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5529 - val_loss: 0.5061\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5225 - val_loss: 0.5058\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4977 - val_loss: 0.5272\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4770 - val_loss: 0.5600\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4600 - val_loss: 0.5367\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4469 - val_loss: 0.5220\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4356 - val_loss: 0.4878\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4264 - val_loss: 0.4531\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4187 - val_loss: 0.4182\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4124 - val_loss: 0.3877\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4064 - val_loss: 0.3818\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4014 - val_loss: 0.4022\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3962 - val_loss: 0.4348\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3926 - val_loss: 0.4934\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3878 - val_loss: 0.5340\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3847 - val_loss: 0.5982\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3819 - val_loss: 0.6543\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3786 - val_loss: 0.7246\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3758 - val_loss: 0.8046\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3735 - val_loss: 0.8587\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3711 - val_loss: 0.9090\n",
      "121/121 [==============================] - 0s 820us/step - loss: 0.3884\n",
      "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=   8.1s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.1014 - val_loss: 2.1643\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7146 - val_loss: 0.6141\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6063 - val_loss: 0.5601\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5633 - val_loss: 0.5241\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5302 - val_loss: 0.5017\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5034 - val_loss: 0.4749\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4814 - val_loss: 0.4558\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4633 - val_loss: 0.4297\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4483 - val_loss: 0.4464\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4374 - val_loss: 0.4189\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4438\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4188 - val_loss: 0.4250\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4121 - val_loss: 0.4009\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4067 - val_loss: 0.4403\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4025 - val_loss: 0.4014\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 0.4247\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3946 - val_loss: 0.3964\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3914 - val_loss: 0.3974\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.4229\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3860 - val_loss: 0.4053\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3840 - val_loss: 0.3989\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3815 - val_loss: 0.3957\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3793 - val_loss: 0.3864\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3774 - val_loss: 0.4022\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3756 - val_loss: 0.3729\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3733 - val_loss: 0.3645\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3716 - val_loss: 0.4107\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3702 - val_loss: 0.3925\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3688 - val_loss: 0.4265\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3677 - val_loss: 0.3879\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3659 - val_loss: 0.3789\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3643 - val_loss: 0.4080\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3631 - val_loss: 0.3873\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3617 - val_loss: 0.4232\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3613 - val_loss: 0.3718\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3593 - val_loss: 0.3663\n",
      "121/121 [==============================] - 0s 794us/step - loss: 0.3555\n",
      "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=  11.1s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.2908 - val_loss: 297.3652\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1716 - val_loss: 539.0367\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.2333 - val_loss: 3736.4509\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 11.9933 - val_loss: 12227.6924\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 54.7040 - val_loss: 61529.0664\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2281.0823 - val_loss: 268363.5000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2760.9944 - val_loss: 1210517.2500\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 40359.3945 - val_loss: 5411005.5000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 83691.9453 - val_loss: 24506694.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1055625.8750 - val_loss: 119813064.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1860448.3750 - val_loss: 529731296.0000\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1402366.0000\n",
      "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=   3.6s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.0446 - val_loss: 15.8284\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5210 - val_loss: 22.4892\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5063 - val_loss: 24.7894\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5101 - val_loss: 22.4864\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5097 - val_loss: 21.9009\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5089 - val_loss: 21.2895\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5113 - val_loss: 19.9064\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5102 - val_loss: 22.5013\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5069 - val_loss: 20.0987\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5087 - val_loss: 10.7128\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5083 - val_loss: 19.7319\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5049 - val_loss: 24.3237\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5077 - val_loss: 25.9485\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5199 - val_loss: 10.5277\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5078 - val_loss: 17.1916\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5064 - val_loss: 21.8346\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5058 - val_loss: 11.7743\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5101 - val_loss: 14.1555\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5071 - val_loss: 20.9814\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5032 - val_loss: 12.3621\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5071 - val_loss: 25.9146\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5132 - val_loss: 16.0461\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5071 - val_loss: 19.4877\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5084 - val_loss: 12.1054\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.7813\n",
      "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=   8.2s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.2328 - val_loss: 307.7495\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9214 - val_loss: 76.3014\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3774 - val_loss: 795.2289\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 34.9847 - val_loss: 704.0445\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3027 - val_loss: 2668.0278\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 9.2431 - val_loss: 1446.2601\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 4.8034 - val_loss: 1540.5377\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 41.9016 - val_loss: 1396.7119\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 10.9509 - val_loss: 1334.0858\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4803 - val_loss: 216.7274\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 13.8366 - val_loss: 125.2068\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6450 - val_loss: 2.2902\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7449 - val_loss: 790.5425\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 9.2398 - val_loss: 468.7425\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.2300 - val_loss: 1073.9153\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 37.3801 - val_loss: 865.6381\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 8.9708 - val_loss: 1128.1495\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.8291 - val_loss: 499.5188\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 24.8681 - val_loss: 309.7941\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.6469 - val_loss: 354.6341\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 4.2841 - val_loss: 559.4487\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 4.5495 - val_loss: 393.8696\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6226\n",
      "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=   9.6s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2632 - val_loss: 1.4543\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6364 - val_loss: 0.9557\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5396 - val_loss: 0.4628\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4783 - val_loss: 0.4214\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4400 - val_loss: 0.3984\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4169 - val_loss: 0.4056\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4004 - val_loss: 0.3741\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3888 - val_loss: 0.3926\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3809 - val_loss: 0.3832\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3743 - val_loss: 0.3929\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3697 - val_loss: 0.3570\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3640 - val_loss: 0.3790\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3595 - val_loss: 0.3840\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3569 - val_loss: 0.3950\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3530 - val_loss: 0.3751\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3503 - val_loss: 0.3955\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3476 - val_loss: 0.3900\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3455 - val_loss: 0.3905\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3420 - val_loss: 0.3944\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3404 - val_loss: 0.3811\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3378 - val_loss: 0.3906\n",
      "121/121 [==============================] - 0s 796us/step - loss: 0.3624\n",
      "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=   7.6s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0130 - val_loss: 0.5822\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5558 - val_loss: 0.4873\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4781 - val_loss: 0.4420\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4376 - val_loss: 0.4139\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4111 - val_loss: 0.4132\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3947 - val_loss: 0.4464\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3840 - val_loss: 0.4717\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3760 - val_loss: 0.5331\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3682 - val_loss: 0.6951\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3633 - val_loss: 0.6944\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3574 - val_loss: 0.8506\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3535 - val_loss: 0.7660\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3509 - val_loss: 0.8731\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 0.9306\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3463 - val_loss: 0.9345\n",
      "121/121 [==============================] - 0s 772us/step - loss: 0.3685\n",
      "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=   5.1s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1090 - val_loss: 0.6796\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5639 - val_loss: 0.4957\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4920 - val_loss: 0.4633\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4547 - val_loss: 0.4565\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4305 - val_loss: 0.4150\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4141 - val_loss: 0.4331\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4026 - val_loss: 0.3887\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3936 - val_loss: 0.3785\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3857 - val_loss: 0.4233\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3819 - val_loss: 0.3652\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3760 - val_loss: 0.4336\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3725 - val_loss: 0.3763\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3683 - val_loss: 0.3632\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3644 - val_loss: 0.4460\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3624 - val_loss: 0.3555\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3584 - val_loss: 0.3947\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3560 - val_loss: 0.3623\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3525 - val_loss: 0.3774\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3505 - val_loss: 0.3807\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3479 - val_loss: 0.3420\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3463 - val_loss: 0.3452\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3446 - val_loss: 0.3273\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3425 - val_loss: 0.3279\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3395 - val_loss: 0.4346\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3401 - val_loss: 0.3432\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3366 - val_loss: 0.3227\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3342 - val_loss: 0.4466\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3358 - val_loss: 0.3322\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3332 - val_loss: 0.3982\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3323 - val_loss: 0.3431\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3294 - val_loss: 0.3346\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3279 - val_loss: 0.3637\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3271 - val_loss: 0.3467\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3243 - val_loss: 0.3582\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3245 - val_loss: 0.3141\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3223 - val_loss: 0.3636\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3220 - val_loss: 0.3376\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3212 - val_loss: 0.5255\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3230 - val_loss: 0.3313\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3194 - val_loss: 0.4033\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3181 - val_loss: 0.3345\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3165 - val_loss: 0.3650\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3162 - val_loss: 0.3311\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3147 - val_loss: 0.3684\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3152 - val_loss: 0.3090\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3128 - val_loss: 0.3821\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3118 - val_loss: 0.3187\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3118 - val_loss: 0.3007\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3094 - val_loss: 0.4102\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3110 - val_loss: 0.3017\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3085 - val_loss: 0.4009\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3088 - val_loss: 0.3086\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3079 - val_loss: 0.3169\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3070 - val_loss: 0.3018\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3060 - val_loss: 0.3036\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3038 - val_loss: 0.3481\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3054 - val_loss: 0.3153\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3048 - val_loss: 0.2978\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3034 - val_loss: 0.3107\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3038 - val_loss: 0.3228\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3022 - val_loss: 0.3199\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3012 - val_loss: 0.3000\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3015 - val_loss: 0.3156\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3008 - val_loss: 0.3358\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3014 - val_loss: 0.3609\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3007 - val_loss: 0.3171\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2991 - val_loss: 0.2975\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2978 - val_loss: 0.3154\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2976 - val_loss: 0.2953\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2961 - val_loss: 0.3082\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2964 - val_loss: 0.2886\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2959 - val_loss: 0.2925\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2954 - val_loss: 0.2969\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2946 - val_loss: 0.2854\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2946 - val_loss: 0.2990\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2928 - val_loss: 0.3339\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2956 - val_loss: 0.2858\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2933 - val_loss: 0.3068\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2934 - val_loss: 0.2878\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2917 - val_loss: 0.2906\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2913 - val_loss: 0.3037\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2916 - val_loss: 0.2966\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2912 - val_loss: 0.2906\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2906 - val_loss: 0.3114\n",
      "121/121 [==============================] - 0s 821us/step - loss: 0.3054\n",
      "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=  28.0s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 2.1150 - val_loss: 29.5063\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0854 - val_loss: 33.7785\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9418 - val_loss: 4.0125\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6369 - val_loss: 0.5556\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5632 - val_loss: 0.5119\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5371 - val_loss: 0.4888\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5149 - val_loss: 0.4729\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4964 - val_loss: 0.4559\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4803 - val_loss: 0.4601\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4670 - val_loss: 0.4303\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4561 - val_loss: 0.4205\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4469 - val_loss: 0.4242\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4391 - val_loss: 0.4107\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4325 - val_loss: 0.4231\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4270 - val_loss: 0.4221\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4221 - val_loss: 0.4084\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4179 - val_loss: 0.4209\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4143 - val_loss: 0.4017\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4106 - val_loss: 0.4322\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4080 - val_loss: 0.4001\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4050 - val_loss: 0.4263\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4027 - val_loss: 0.4032\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4002 - val_loss: 0.4039\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 0.3764\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3962 - val_loss: 0.4241\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3944 - val_loss: 0.3779\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3925 - val_loss: 0.4126\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3910 - val_loss: 0.3967\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3889 - val_loss: 0.4045\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3880 - val_loss: 0.3748\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3864 - val_loss: 0.3717\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3851 - val_loss: 0.3676\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.4054\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3825 - val_loss: 0.3924\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3815 - val_loss: 0.3611\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3800 - val_loss: 0.4182\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3792 - val_loss: 0.3539\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3779 - val_loss: 0.4403\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3769 - val_loss: 0.3551\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3757 - val_loss: 0.4125\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3748 - val_loss: 0.3665\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3735 - val_loss: 0.3591\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3730 - val_loss: 0.3570\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3717 - val_loss: 0.4125\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3714 - val_loss: 0.3547\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3699 - val_loss: 0.3779\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3692 - val_loss: 0.3886\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3877\n",
      "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=  14.6s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.8463 - val_loss: 0.7805\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7088 - val_loss: 1.1550\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6196 - val_loss: 1.8115\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5692 - val_loss: 2.6113\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5319 - val_loss: 3.2626\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5046 - val_loss: 3.5247\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4841 - val_loss: 3.5926\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4679 - val_loss: 3.5562\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4551 - val_loss: 2.9541\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4459 - val_loss: 2.5606\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4377 - val_loss: 2.1560\n",
      "121/121 [==============================] - 0s 775us/step - loss: 0.4866\n",
      "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=   4.3s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.7445 - val_loss: 2.5834\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7268 - val_loss: 3.5564\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6419 - val_loss: 1.7895\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6134 - val_loss: 1.7436\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5564 - val_loss: 0.6344\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5303 - val_loss: 0.8713\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5070 - val_loss: 0.5604\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4919 - val_loss: 0.4695\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4759 - val_loss: 0.4942\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4659 - val_loss: 0.4375\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4561 - val_loss: 0.4536\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4481 - val_loss: 0.4276\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4408 - val_loss: 0.4084\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4354 - val_loss: 0.4897\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4300 - val_loss: 0.4018\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4246 - val_loss: 0.5505\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4211 - val_loss: 0.4602\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4171 - val_loss: 0.4347\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4132 - val_loss: 0.3835\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4092 - val_loss: 0.4115\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4065 - val_loss: 0.3817\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4035 - val_loss: 0.3737\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4008 - val_loss: 0.3720\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3983 - val_loss: 0.4318\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3970 - val_loss: 0.4158\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3943 - val_loss: 0.3821\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3922 - val_loss: 0.4069\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3909 - val_loss: 0.4024\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.5904\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3898 - val_loss: 0.4027\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3858 - val_loss: 0.4216\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3847 - val_loss: 0.3603\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3825 - val_loss: 0.4134\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3819 - val_loss: 0.3633\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.3542\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3786 - val_loss: 0.3568\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3783 - val_loss: 0.4216\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3770 - val_loss: 0.5522\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3792 - val_loss: 0.5648\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3763 - val_loss: 0.6416\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3785 - val_loss: 0.3847\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3729 - val_loss: 0.5255\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3744 - val_loss: 0.7023\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3741 - val_loss: 0.7508\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3771 - val_loss: 0.5608\n",
      "121/121 [==============================] - 0s 963us/step - loss: 0.3745\n",
      "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=  14.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0682 - val_loss: 6.4183\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7154 - val_loss: 16.7917\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5830 - val_loss: 4.7824\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4475 - val_loss: 8.6078\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4779 - val_loss: 1.8032\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4008 - val_loss: 0.3655\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3682 - val_loss: 0.3783\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3591 - val_loss: 0.4054\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3533 - val_loss: 0.3909\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3488 - val_loss: 0.3907\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3445 - val_loss: 0.3554\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3395 - val_loss: 0.3610\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3352 - val_loss: 0.3665\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3334 - val_loss: 0.3635\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3294 - val_loss: 0.3581\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3272 - val_loss: 0.3566\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3240 - val_loss: 0.3580\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3224 - val_loss: 0.3482\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3187 - val_loss: 0.3540\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3166 - val_loss: 0.3416\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3148 - val_loss: 0.3364\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3122 - val_loss: 0.3554\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3099 - val_loss: 0.3327\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3093 - val_loss: 0.3086\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3047 - val_loss: 0.3491\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3032 - val_loss: 0.3064\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3027 - val_loss: 0.3316\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3019 - val_loss: 0.3428\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2984 - val_loss: 0.3363\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2965 - val_loss: 0.2970\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2955 - val_loss: 0.3073\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2934 - val_loss: 0.2944\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2909 - val_loss: 0.3182\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2890 - val_loss: 0.3236\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2879 - val_loss: 0.2904\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2865 - val_loss: 0.3637\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2858 - val_loss: 0.3502\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2857 - val_loss: 0.3625\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2839 - val_loss: 0.2941\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2820 - val_loss: 0.3314\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2806 - val_loss: 0.2905\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2793 - val_loss: 0.2891\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2785 - val_loss: 0.2901\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2766 - val_loss: 0.3148\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2766 - val_loss: 0.3174\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2756 - val_loss: 0.3225\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2736 - val_loss: 0.3003\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2734 - val_loss: 0.2856\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2709 - val_loss: 0.2755\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2710 - val_loss: 0.3360\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2695 - val_loss: 0.3228\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2685 - val_loss: 0.3241\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2680 - val_loss: 0.2814\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2664 - val_loss: 0.2853\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2650 - val_loss: 0.2956\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2656 - val_loss: 0.2760\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2636 - val_loss: 0.3283\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2643 - val_loss: 0.2748\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2631 - val_loss: 0.2886\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2610 - val_loss: 0.2774\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2623 - val_loss: 0.3505\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2609 - val_loss: 0.2820\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2600 - val_loss: 0.3182\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2597 - val_loss: 0.3008\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2578 - val_loss: 0.2737\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2580 - val_loss: 0.2799\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2584 - val_loss: 0.3738\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2577 - val_loss: 0.2719\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2574 - val_loss: 0.3467\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2575 - val_loss: 0.2839\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2563 - val_loss: 0.4576\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2567 - val_loss: 0.2928\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2541 - val_loss: 0.3401\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2534 - val_loss: 0.2755\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2530 - val_loss: 0.3753\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2526 - val_loss: 0.2755\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2539 - val_loss: 0.3902\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2535 - val_loss: 0.3194\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3093\n",
      "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=  27.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8717 - val_loss: 0.7369\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5007 - val_loss: 0.4431\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4272 - val_loss: 0.3919\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3961 - val_loss: 0.3834\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3777 - val_loss: 0.3951\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3661 - val_loss: 0.4650\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3580 - val_loss: 0.6408\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3524 - val_loss: 0.7273\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3462 - val_loss: 0.9105\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.6967\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3364 - val_loss: 0.6960\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3327 - val_loss: 0.7798\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3293 - val_loss: 0.8549\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3277 - val_loss: 0.8288\n",
      "121/121 [==============================] - 0s 735us/step - loss: 0.3525\n",
      "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=   5.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9177 - val_loss: 0.9196\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4767 - val_loss: 2.1025\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4329 - val_loss: 3.5511\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4408 - val_loss: 1.5867\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3910 - val_loss: 0.4227\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3715 - val_loss: 0.3738\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3634 - val_loss: 0.3350\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3569 - val_loss: 0.3384\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3518 - val_loss: 0.3720\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3514 - val_loss: 0.3276\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3456 - val_loss: 0.3969\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3420 - val_loss: 0.3330\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3373 - val_loss: 0.3226\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3347 - val_loss: 0.3670\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3323 - val_loss: 0.3203\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3294 - val_loss: 0.3560\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3269 - val_loss: 0.3220\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3243 - val_loss: 0.3558\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3224 - val_loss: 0.3367\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3193 - val_loss: 0.3597\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3180 - val_loss: 0.3132\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3156 - val_loss: 0.3189\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3132 - val_loss: 0.3583\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3116 - val_loss: 0.3063\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3101 - val_loss: 0.3311\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3072 - val_loss: 0.3174\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3055 - val_loss: 0.3112\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3044 - val_loss: 0.3299\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3049 - val_loss: 0.3993\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3039 - val_loss: 0.3113\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2999 - val_loss: 0.3272\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2978 - val_loss: 0.3015\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2981 - val_loss: 0.3462\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2974 - val_loss: 0.2964\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2936 - val_loss: 0.2972\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2910 - val_loss: 0.3549\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2905 - val_loss: 0.3539\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2930 - val_loss: 0.4022\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2915 - val_loss: 0.3154\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2909 - val_loss: 0.3909\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2873 - val_loss: 0.3042\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2858 - val_loss: 0.3215\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2882 - val_loss: 0.2828\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2843 - val_loss: 0.3319\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2842 - val_loss: 0.2950\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2813 - val_loss: 0.3195\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2802 - val_loss: 0.2817\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2801 - val_loss: 0.2868\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2794 - val_loss: 0.3575\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2781 - val_loss: 0.2966\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2770 - val_loss: 0.3577\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2764 - val_loss: 0.2973\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2758 - val_loss: 0.3002\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2757 - val_loss: 0.3002\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2741 - val_loss: 0.2820\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2740 - val_loss: 0.3077\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2729 - val_loss: 0.3363\n",
      "121/121 [==============================] - 0s 877us/step - loss: 0.2931\n",
      "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=  22.0s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9615 - val_loss: 10.9251\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5921 - val_loss: 3.3912\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4539 - val_loss: 0.4039\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3914 - val_loss: 0.3693\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3713 - val_loss: 0.3554\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3601 - val_loss: 0.3874\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3523 - val_loss: 0.3635\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3454 - val_loss: 0.3985\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3410 - val_loss: 0.3793\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3381 - val_loss: 0.3706\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3350 - val_loss: 0.3313\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3304 - val_loss: 0.3509\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3269 - val_loss: 0.3794\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3260 - val_loss: 0.3319\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3217 - val_loss: 0.3482\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3194 - val_loss: 0.3491\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3172 - val_loss: 0.3249\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3156 - val_loss: 0.3434\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3123 - val_loss: 0.3348\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3108 - val_loss: 0.3241\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3086 - val_loss: 0.3745\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3082 - val_loss: 0.3088\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3047 - val_loss: 0.4155\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3080 - val_loss: 0.3835\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3038 - val_loss: 0.3595\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2992 - val_loss: 0.3133\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2983 - val_loss: 0.3367\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2973 - val_loss: 0.3549\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2944 - val_loss: 0.3442\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2932 - val_loss: 0.3234\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2933 - val_loss: 0.3159\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2900 - val_loss: 0.3048\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2873 - val_loss: 0.3223\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2854 - val_loss: 0.3019\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2844 - val_loss: 0.2926\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2838 - val_loss: 0.3520\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2827 - val_loss: 0.2986\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2829 - val_loss: 0.3689\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2812 - val_loss: 0.3030\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2791 - val_loss: 0.3376\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2788 - val_loss: 0.2860\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2776 - val_loss: 0.3230\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2767 - val_loss: 0.3010\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2746 - val_loss: 0.3257\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2741 - val_loss: 0.2834\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2728 - val_loss: 0.3418\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2713 - val_loss: 0.3279\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2718 - val_loss: 0.2819\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2690 - val_loss: 0.2761\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2693 - val_loss: 0.3422\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2682 - val_loss: 0.3317\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2661 - val_loss: 0.3510\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2684 - val_loss: 0.2790\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2651 - val_loss: 0.3185\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2635 - val_loss: 0.3131\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2639 - val_loss: 0.2954\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2623 - val_loss: 0.3419\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2630 - val_loss: 0.3006\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2620 - val_loss: 0.2866\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3019\n",
      "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=  24.3s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8381 - val_loss: 0.6551\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4570 - val_loss: 0.4129\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4107 - val_loss: 0.6097\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3911 - val_loss: 0.6574\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3755 - val_loss: 0.6379\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3647 - val_loss: 0.8601\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3603 - val_loss: 1.0613\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3515 - val_loss: 1.1190\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3456 - val_loss: 1.2255\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3424 - val_loss: 0.8015\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3373 - val_loss: 0.8351\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3338 - val_loss: 0.7639\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3595\n",
      "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=   4.8s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8683 - val_loss: 2.2007\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5072 - val_loss: 3.3028\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4486 - val_loss: 0.9130\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4071 - val_loss: 0.5328\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3842 - val_loss: 0.3609\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3729 - val_loss: 0.4151\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3659 - val_loss: 0.3580\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3596 - val_loss: 0.3516\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3528 - val_loss: 0.3983\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3511 - val_loss: 0.3323\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3445 - val_loss: 0.4228\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3420 - val_loss: 0.3283\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3375 - val_loss: 0.3463\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3337 - val_loss: 0.4041\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3326 - val_loss: 0.3275\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3291 - val_loss: 0.3800\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3263 - val_loss: 0.3212\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3228 - val_loss: 0.3300\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3216 - val_loss: 0.3821\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3190 - val_loss: 0.3409\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3179 - val_loss: 0.3752\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3181 - val_loss: 0.3093\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3147 - val_loss: 0.3417\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3132 - val_loss: 0.3245\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3099 - val_loss: 0.3051\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3072 - val_loss: 0.3033\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3047 - val_loss: 0.4346\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3079 - val_loss: 0.3420\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3058 - val_loss: 0.3843\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3035 - val_loss: 0.3311\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3004 - val_loss: 0.3117\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2978 - val_loss: 0.4216\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2987 - val_loss: 0.3041\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2941 - val_loss: 0.3648\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2963 - val_loss: 0.3054\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2923 - val_loss: 0.3757\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3017\n",
      "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=  13.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2259 - val_loss: 0.5753\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5658 - val_loss: 8.9878\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5484 - val_loss: 11.0986\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5602 - val_loss: 1.1306\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4336 - val_loss: 0.5256\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4072 - val_loss: 0.4498\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3939 - val_loss: 0.4056\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3835 - val_loss: 0.3999\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3766 - val_loss: 0.3957\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3712 - val_loss: 0.3904\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3672 - val_loss: 0.3688\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3630 - val_loss: 0.3651\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3587 - val_loss: 0.3709\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3579 - val_loss: 0.3816\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3534 - val_loss: 0.3620\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3528 - val_loss: 0.3670\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3490 - val_loss: 0.3671\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3474 - val_loss: 0.3605\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3445 - val_loss: 0.3552\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3421 - val_loss: 0.3538\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3417 - val_loss: 0.3520\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3388 - val_loss: 0.3477\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3372 - val_loss: 0.3509\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3374 - val_loss: 0.3304\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3333 - val_loss: 0.3683\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3334 - val_loss: 0.3246\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3336 - val_loss: 0.3389\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3322 - val_loss: 0.3366\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3279 - val_loss: 0.3387\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3276 - val_loss: 0.3212\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3255 - val_loss: 0.3219\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3256 - val_loss: 0.3151\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3239 - val_loss: 0.3458\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3221 - val_loss: 0.3163\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3209 - val_loss: 0.3140\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3191 - val_loss: 0.3896\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3189 - val_loss: 0.3819\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3190 - val_loss: 0.3408\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3160 - val_loss: 0.3145\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3154 - val_loss: 0.3381\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3187 - val_loss: 0.3158\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3149 - val_loss: 0.3136\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3148 - val_loss: 0.3110\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3112 - val_loss: 0.3381\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3145 - val_loss: 0.3052\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3103 - val_loss: 0.3269\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3089 - val_loss: 0.3292\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3120 - val_loss: 0.3221\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3075 - val_loss: 0.3022\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3069 - val_loss: 0.3504\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3059 - val_loss: 0.3324\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3047 - val_loss: 0.3397\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3052 - val_loss: 0.3061\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3034 - val_loss: 0.3104\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3032 - val_loss: 0.3363\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3042 - val_loss: 0.2997\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3014 - val_loss: 0.3759\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3035 - val_loss: 0.3257\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3001 - val_loss: 0.2981\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2991 - val_loss: 0.3213\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2997 - val_loss: 0.3224\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2982 - val_loss: 0.3493\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2985 - val_loss: 0.3085\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2963 - val_loss: 0.3977\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2965 - val_loss: 0.2958\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3032 - val_loss: 0.3222\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2951 - val_loss: 0.3343\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2942 - val_loss: 0.3023\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2942 - val_loss: 0.3624\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2968 - val_loss: 0.2944\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2921 - val_loss: 0.3878\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2922 - val_loss: 0.3014\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2911 - val_loss: 0.2961\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2900 - val_loss: 0.3862\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2909 - val_loss: 0.3031\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2891 - val_loss: 0.3306\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2927 - val_loss: 0.3871\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2904 - val_loss: 0.6477\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2952 - val_loss: 0.3554\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2882 - val_loss: 0.4867\n",
      "121/121 [==============================] - 0s 921us/step - loss: 0.3230\n",
      "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  32.6s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1975 - val_loss: 0.8898\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5319 - val_loss: 0.5270\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4524 - val_loss: 0.4844\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4199 - val_loss: 0.4250\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4023 - val_loss: 0.3735\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3907 - val_loss: 0.3859\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3833 - val_loss: 0.4576\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3754 - val_loss: 0.4926\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3691 - val_loss: 0.6246\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3660 - val_loss: 0.5262\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3611 - val_loss: 0.5952\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3570 - val_loss: 0.6355\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3550 - val_loss: 0.7437\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3530 - val_loss: 0.7101\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3502 - val_loss: 0.6821\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3613\n",
      "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  11.1s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1315 - val_loss: 2.8528\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6016 - val_loss: 2.3412\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5108 - val_loss: 0.9015\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4594 - val_loss: 0.8313\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4291 - val_loss: 0.5217\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4115 - val_loss: 0.4956\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4016 - val_loss: 0.3745\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3917 - val_loss: 0.4012\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3848 - val_loss: 0.4169\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3815 - val_loss: 0.3843\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3756 - val_loss: 0.6122\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3743 - val_loss: 0.3579\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3671 - val_loss: 0.3497\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3632 - val_loss: 0.5161\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3635 - val_loss: 0.4273\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3592 - val_loss: 0.5739\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3601 - val_loss: 0.4975\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3547 - val_loss: 0.4886\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3535 - val_loss: 0.3371\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3485 - val_loss: 0.4118\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3485 - val_loss: 0.3310\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3460 - val_loss: 0.3289\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3435 - val_loss: 0.3287\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 0.5224\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3438 - val_loss: 0.7689\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3423 - val_loss: 0.8909\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3448 - val_loss: 0.4864\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3369 - val_loss: 0.6169\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3373 - val_loss: 0.3470\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3327 - val_loss: 0.5750\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3332 - val_loss: 0.3685\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3308 - val_loss: 0.7292\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3345 - val_loss: 0.3932\n",
      "121/121 [==============================] - 0s 770us/step - loss: 0.3362\n",
      "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  12.3s\n",
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.8194 - val_loss: 1.8036\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4857 - val_loss: 2.0827\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.3796\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3857 - val_loss: 0.4283\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3740 - val_loss: 0.3617\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3620 - val_loss: 0.4566\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3566 - val_loss: 0.3573\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3492 - val_loss: 0.3380\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3432 - val_loss: 0.3757\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3389 - val_loss: 0.4069\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3380 - val_loss: 0.5455\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3368 - val_loss: 0.6470\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3319 - val_loss: 0.3109\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3257 - val_loss: 0.3199\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3240 - val_loss: 0.3064\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3203 - val_loss: 0.3244\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3175 - val_loss: 0.3988\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3153 - val_loss: 0.2991\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3139 - val_loss: 0.3078\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3112 - val_loss: 0.4431\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3111 - val_loss: 0.3272\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3076 - val_loss: 0.5079\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3067 - val_loss: 0.5685\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3050 - val_loss: 0.5935\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3037 - val_loss: 0.2993\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2997 - val_loss: 0.6029\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3006 - val_loss: 0.5141\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3012 - val_loss: 0.4030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x156f1cef0>,\n",
       "                   param_distributions={'learning_rate': [0.001683454924600351,\n",
       "                                                          0.02390836445593178,\n",
       "                                                          0.008731907739399206,\n",
       "                                                          0.004725396149933917,\n",
       "                                                          0.0006154014789262348,\n",
       "                                                          0.0006153331256530192,\n",
       "                                                          0.0003920021771415983,\n",
       "                                                          0.01619845322936229,\n",
       "                                                          0.004779156784872302,\n",
       "                                                          0.007821074275112298,\n",
       "                                                          0.0...\n",
       "                                                          0.005021425736625637,\n",
       "                                                          0.0005703073595961105,\n",
       "                                                          0.001151888789941251,\n",
       "                                                          0.001621231156394198,\n",
       "                                                          0.0024505367684280487,\n",
       "                                                          0.011155092541719619,\n",
       "                                                          0.0007524347058135697,\n",
       "                                                          0.0032032448128444043,\n",
       "                                                          0.004591455636549438,\n",
       "                                                          0.0003715541189658278, ...],\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29, 30, ...]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100)               .tolist(),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2)      .rvs(1000).tolist(),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnd_search_cv.best_params_ {'n_neurons': 74, 'n_hidden': 3, 'learning_rate': 0.005803602934201024}\n",
      "rnd_search_cv.best_score_ -0.31833014885584515\n",
      "rnd_search_cv.best_estimator_ <keras.wrappers.scikit_learn.KerasRegressor object at 0x15b88d630>\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3029\n",
      "rnd_search_cv.score(X_test, y_test) -0.30288204550743103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x159d874a8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"rnd_search_cv.best_params_\",rnd_search_cv.best_params_)\n",
    "print(\"rnd_search_cv.best_score_\",rnd_search_cv.best_score_)\n",
    "print(\"rnd_search_cv.best_estimator_\",rnd_search_cv.best_estimator_)\n",
    "print(\"rnd_search_cv.score(X_test, y_test)\",rnd_search_cv.score(X_test, y_test))\n",
    "\n",
    "model = rnd_search_cv.best_estimator_.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.30288204550743103"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3 (v3.7.3:ef4ec6ed12, Mar 25 2019, 16:52:21) \n[Clang 6.0 (clang-600.0.57)]"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
